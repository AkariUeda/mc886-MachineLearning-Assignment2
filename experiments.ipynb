{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZmBghBfFBLo"
   },
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLO8uWuGFBLs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZUB2PHqFBL2"
   },
   "source": [
    "## Descrição do problema\n",
    "\n",
    "* Temos 60k imagens divididas entre 9 classes. Cada imagem possui 784 pixels que variam do valor 0 (preto) a 255 (branco).\n",
    "* O dataset já foi randomizado previamente e apenas uma vez, utilizando o código comentado abaixo. Dividimos entre conjunto de treino (50k) e validação (10k).\n",
    "* Por se tratar de imagens, em que os valores de todas as features são semelhantes, não aplicamos nenhuma técnica de normalização ou detecção de outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zy3bvjMcFBL6"
   },
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "# dataset = dataset.sample(frac=1)\n",
    "# dataset = np.array(dataset)\n",
    "# train_set    = dataset[0:50000,  2:]\n",
    "# valid_set    = dataset[50000:,2:]\n",
    "# train_labels = dataset[0:50000,1]\n",
    "# valid_labels = dataset[50000:,1]\n",
    "# np.savetxt('fashion-mnist_valid-set.csv', valid_set, delimiter=',',fmt='%i')\n",
    "# np.savetxt('fashion-mnist_train-labels.csv', train_labels, delimiter=',',fmt='%i')\n",
    "# np.savetxt('fashion-mnist_valid-labels.csv', valid_labels, delimiter=',',fmt='%i')\n",
    "# np.savetxt('fashion-mnist_train-set.csv', train_set, delimiter=',',fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YWmEkJUFBMA"
   },
   "outputs": [],
   "source": [
    "train_set    = np.genfromtxt('fashion-mnist_train-set.csv', delimiter=',')\n",
    "valid_set    = np.genfromtxt('fashion-mnist_valid-set.csv', delimiter=',')\n",
    "train_labels = np.genfromtxt('fashion-mnist_train-labels.csv', delimiter=',')\n",
    "valid_labels = np.genfromtxt('fashion-mnist_valid-labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAmKx3UbFBMI"
   },
   "outputs": [],
   "source": [
    "def normalize_features(features, mean, std):\n",
    "    output = np.copy(features)\n",
    "    output = np.subtract(output, mean)\n",
    "    output = np.divide(output, std)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RE2ZcCboFBMO"
   },
   "outputs": [],
   "source": [
    "mean = np.mean(train_set, axis=0)\n",
    "std = np.std(train_set, axis=0)\n",
    "train_set = normalize_features(train_set, mean, std)\n",
    "valid_set = normalize_features(valid_set, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrdIaAv4FBMS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMknghDWFBMY"
   },
   "source": [
    "### Pequena amostra das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtTbgsMNFBMa"
   },
   "outputs": [],
   "source": [
    "# img = Image.fromarray(train_set[8].reshape(28, 28).astype('uint8')*255)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhUNUN-7FBMi"
   },
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5p8GJGSSFBMo"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = np.multiply(z, -1)\n",
    "    g = np.exp(g)\n",
    "    g = np.add(g, 1)\n",
    "    g = np.true_divide(1,g)\n",
    "    g[g == 1] = 0.9999\n",
    "    g[g == 0] = 0.0001\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHaeWK0_FBMu"
   },
   "source": [
    "## Logistic-Regression - One vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV55rDjGFBMw"
   },
   "outputs": [],
   "source": [
    "def train_lr(theta, X, Y, iteracoes, alpha):\n",
    "    dash = '-' * 40\n",
    "    costs = []\n",
    "    n = len(theta)\n",
    "    m = len(X)\n",
    "    Xt = np.transpose(X)\n",
    "    grad = alpha*(1/m)\n",
    "\n",
    "    j=0\n",
    "    for i in range(0,iteracoes):\n",
    "        H = sigmoid(np.dot(X, theta))\n",
    "        loss = np.mean(np.subtract(np.multiply(np.multiply(-1, Y),np.log(H)),np.multiply(np.subtract(1, Y),np.log(np.subtract(1,H)))))\n",
    "        #loss = (1 / m) * (-Y.T.dot(np.log(H)) - (1 - Y).T.dot(np.log(1 - H)))\n",
    "        #print(loss)\n",
    "        J = np.subtract(H,Y)\n",
    "        J = np.dot(Xt, J)\n",
    "        new_theta = np.zeros(n)\n",
    "        J = np.multiply(grad,J)\n",
    "        new_theta = np.subtract(theta,J)\n",
    "        theta = new_theta\n",
    "        costs.append(loss)\n",
    "        if j==9:\n",
    "            print(\"Iteração: \"+str(i+1)+\" loss:\"+str(loss))\n",
    "            j=0\n",
    "        j+=1\n",
    "\n",
    "    predict = sigmoid(np.dot(X, theta))\n",
    "    predict[predict >= 0.5] = 1\n",
    "    predict[predict < 0.5] = 0\n",
    "    hits = np.sum(predict == Y)\n",
    "    accuracy = hits/len(Y)\n",
    "    print(\"Acurácia: \"+str(accuracy))\n",
    "    plt.plot(range(0,iteracoes),costs)\n",
    "    plt.ylabel('Custo')\n",
    "    plt.xlabel('Iterações')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3XkooYrFBM4"
   },
   "source": [
    "## Class 0 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xci9Tl6HFBM6"
   },
   "outputs": [],
   "source": [
    "theta = np.random.rand(train_set_n.shape[1])\n",
    "y = np.zeros((train_labels.shape))\n",
    "y[train_labels == 0] = 1\n",
    "y[train_labels != 0] = 0\n",
    "train_lr(theta, train_set_n, y, 1000, 0.02)\n",
    "\n",
    "theta_class0 = theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9wkfcsSFBNI"
   },
   "source": [
    "## Class 1 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rUe3L47FBNK"
   },
   "outputs": [],
   "source": [
    "theta = np.random.rand(train_set_n.shape[1])\n",
    "y = np.zeros((train_labels.shape))\n",
    "y[train_labels == 1] = 1\n",
    "y[train_labels != 1] = 0\n",
    "train_lr(theta, train_set_n, y, 100, 0.02)\n",
    "\n",
    "theta_class1 = theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWjR4mLGFBNS"
   },
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2C8zlAqFBNW"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.max(x,0)\n",
    "\n",
    "def reluDerivative(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    div = np.multiply(x, -1)\n",
    "    div = np.exp(div)\n",
    "    g = np.add(div, 1)\n",
    "    g = np.power(g,2)\n",
    "    g = np.true_divide(div,g)\n",
    "    return g\n",
    "\n",
    "def softmax(x):\n",
    "    s = np.exp(x)\n",
    "    s = np.true_divide(s,np.sum(s))\n",
    "    return s\n",
    "\n",
    "#def softmaxDerivative(x):\n",
    "\n",
    "def identidade(x):\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRPsN9vlFBNa"
   },
   "outputs": [],
   "source": [
    "def backward(self, X, y, o):\n",
    "    # backward propgate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "    self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "    self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.z2.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6J9DRIuFBNe"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, random, input_size, output_size):\n",
    "        if random == True:\n",
    "            self.weights = np.random.rand(input_size, output_size)\n",
    "        else:\n",
    "            self.weights = np.identity(input_size)\n",
    "\n",
    "    def forward(self, layer_input, activation_function):\n",
    "        z = np.dot(layer_input, self.weights)\n",
    "        self.activation = activation_function(z)\n",
    "    \n",
    "    def backward(self, next_layer_error, derivative_function, learning_rate):\n",
    "        self.error = np.dot(np.transpose(next_layer_error), self.weights)\n",
    "        self.delta = self.error * derivative_function(self.activation)\n",
    "        self.weights += self.activation.T.dot(next_layer_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAKI2G3rFBNi"
   },
   "source": [
    "### Criando uma rede neural para regressão logística\n",
    "\n",
    "* Camada 0: Camada de input = train_set_n (50000, 784)\n",
    "* Camada 1: Camada de pesos = Layer() de dimensões (784,)\n",
    "* Camada 2: Camada de saída = h(x), dimensões (5000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqiGCFB7FBNm"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b932dc09b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Adicionando a camada de input no indice 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mneural_net_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mneural_net_logistic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentidade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "neural_net_logistic = []\n",
    "\n",
    "# Adicionando a camada de input no indice 0\n",
    "neural_net_logistic.append(Layer(False, train_set.shape[1], train_set.shape[1]))\n",
    "neural_net_logistic[0].forward(train_set, identidade)\n",
    "\n",
    "# Adicionando a camada de saída no índice 1\n",
    "neural_net_logistic.append(Layer(True, neural_net_logistic[0].activation.shape[1], neural_net_logistic[0].activation.shape[1]//2 ))\n",
    "neural_net_logistic[1].forward(neural_net_logistic[0].activation, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50000,392) (50000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-77876e9ab55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net_logistic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50000,392) (50000,) "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHRfemVIFBN6"
   },
   "outputs": [],
   "source": [
    "def backpropagation(neural_net, y):\n",
    "    total_error = y - neural_net[-1]\n",
    "    total_error = total_error*sigmoidDerivative(neural_net[-1])\n",
    "    \n",
    "    for i in reversed(range(0, len(neural_net))):\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lei8fDMPFBOA",
    "outputId": "1e91a023-df3f-4816-e56c-30b9aa09bd54"
   },
   "outputs": [],
   "source": [
    "backpropagation(neural_net_logistic, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ImZaq3dFBOK"
   },
   "outputs": [],
   "source": [
    "def backward(self, X, y, o):\n",
    "    # backward propgate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "    self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "    self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.z2.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEPn6PqqFBOM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scW9P-DSFBOS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "experiments.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
